# anti-NSFW-detection-test
一些尝试用于对抗色情图片检测算法的思路

## 背景

诸如新浪微博和tumblr之类的网站都会对用户上传的图片进行检测，以屏蔽掉某些不合时宜的（Not Suitable for Work）图片。尽管对于某些以此为生的媒体来说这无异于灭顶之灾，但对普通用户而言，类似的检测算法却影响甚小。即便如此，你仍然会感到不爽，尤其是某些时候你想要分享的性感图片也被屏蔽掉。所以使用了一些图片对新浪微博/Tencent AI/Baidu AI的检测算法进行了测试，得出了一些（可能）可行的对抗检测的思路。

## 一些对抗思路

1. 旋转。
   因为基于CNN的检测算法通常是旋转不鲁棒的，所以可以通过将图片旋转一定的角度用于改变概率的预测值。
   在早期时，某些平台的检测算法确实存在此问题，但是这一问题很快就被修复。在训练CNN模型时，只需要增加对图片的随机旋转增广就可以改善模型的旋转鲁棒性。
   
   以Tencent AI的色情图片检测为例，将示例图片分别旋转90°和180°之后进行测试，porn的概率反而越来越大。这说明了这一种思路目前已经不太可行。
   ![不同旋转角度下的检测结果比对示意图](/images/image_at_different_degrees.jpg)
   
2. 拼接空白图片
   多数情况下CNN对于输入图片的尺寸是有限制的，因此在对图片进行检测时一般会首先将其缩放为1:1的正方形图片，然后再进行检测。针对这样的图片预处理方法，我们可以将原始图片和一张较长的空白图片拼接在一起组成一张长宽比远大于1的图片。这样的图片在缩放成正方形后会偏离模型训练数据集的数据分布，因此可以起到对抗的作用。
   然而这样方式也可以很快得到修复。对于长宽比大大偏离1:1的图片，我们只需要将图片切分为多张1:1的图片然后分别对其检测即可。
   
   对于这样的对抗方式，从下面的示意图可以看出Baidu AI和Tencent AI可能因为处理方式不同而得出了截然不同的检测结果。
   
   ![不同平台下的长图检测结果对比示意图](/images/leng_image_at_different_platforms.jpg)
  
