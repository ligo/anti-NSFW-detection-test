# anti-NSFW-detection-test
一些尝试用于对抗色情图片检测算法的思路

## 背景

诸如新浪微博和tumblr之类的网站都会对用户上传的图片进行检测，以屏蔽掉某些不合时宜的（Not Suitable for Work）图片。尽管对于某些以此为生的媒体来说这无异于灭顶之灾，但对普通用户而言，类似的检测算法却影响甚小。即便如此，你仍然会感到不爽，尤其是某些时候你想要分享的性感图片也被屏蔽掉。所以使用了一些图片对新浪微博/Tencent AI/Baidu AI的检测算法进行了测试，得出了一些（可能）可行的对抗检测的思路。

## 一些对抗思路

1. 旋转。

   因为基于CNN的检测算法通常是旋转不鲁棒的，所以可以通过将图片旋转一定的角度用于改变概率的预测值。
   
   在早期时，某些平台的检测算法确实存在此问题，但是这一问题很快就被修复。在训练CNN模型时，只需要增加对图片的随机旋转增广就可以改善模型的旋转鲁棒性。
   
   以Tencent AI的色情图片检测为例，将示例图片分别旋转90°和180°之后进行测试，porn的概率反而越来越大。这说明了这一种思路目前已经不太可行。
   
   ![不同旋转角度下的检测结果比对示意图](/images/image_at_different_degrees.jpg)
   
2. 拼接空白图片

   多数情况下CNN对于输入图片的尺寸是有限制的，因此在对图片进行检测时一般会首先将其缩放为1:1的正方形图片，然后再进行检测。针对这样的图片预处理方法，我们可以将原始图片和一张较长的空白图片拼接在一起组成一张长宽比远大于1的图片。这样的图片在缩放成正方形后会偏离模型训练数据集的数据分布，因此可以起到对抗的作用。
   
   然而这样方式也可以很快得到修复。对于长宽比大大偏离1:1的图片，我们只需要将图片切分为多张1:1的图片然后分别对其检测即可。
   
   对于这样的对抗方式，从下面的示意图可以看出Baidu AI和Tencent AI可能因为处理方式不同而得出了截然不同的检测结果。
   
   ![不同平台下的长图检测结果对比示意图](/images/leng_image_at_different_platforms.jpg)
   
   P.S. 目前，新浪的算法对这种对抗方式也没有进行针对性改进。
   P.P.S. 将多张图片拼接在一起也可以对抗算法的检测，但是由于大部分平台会对长图进行大幅度的压缩，因此会有较为严重的质量损失，所以拼接空白图片可能更好。
   P.P.P.S. 这样的一种对抗思路应该不难想到，但是由于针对性的处理方法会增加数倍的计算量，这可能是平台没有进行改进的原因。
  
3. 转为gif图片
   
   将一张空白的图片和一张目标图片分别作为gif图片的两帧，空白帧设置较短的时长，目标图片设置为较长的时长。这样得到的gif图片在点击查看时的效果和正常图片差别很小（缺点是图片的体积大大增加）。
   
   这样的对抗方式理论上非常容易检测到，算法只需要将gif逐帧解析，逐帧分析计算，最后返回最大概率即可。
   
   然而事实是，Baidu AI提供了针对gif色情图片的检测（其接口说明：该请求用于鉴定GIF图片的色情度，对于非gif接口，请使用图像审核组合接口。接口会对图片中每一帧进行识别，并返回所有检测结果中色情值最大的为结果。目前支持三个维度：色情、性感、正常。），Tencent AI不支持gif格式的图片，新浪微博也没有对此进行改进。
   
   ![gif图片示意图](/images/model.gif)
   
   P.P.P.P.S. 正如之前提到的，对此类对抗行为针对性的改进会大大增加平台的计算开销。考虑到微博上有非常多的正常图片（搞笑gif或者视频转置的gif等等）均为gif格式，要对所有的gif进行类似的检测会增加很多成本。
   
4. 


5. 
